{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = 'images_dataset_final/'\n",
    "last_pagination = 4\n",
    "\n",
    "if not os.path.exists(dirName):\n",
    "    os.mkdir(dirName)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "headers_std = {\n",
    "'User-Agent': \n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',\n",
    "'Content-Type': 'text/html',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = pd.read_csv('queries.csv')\n",
    "item_cat = inp.item_category\n",
    "\n",
    "for i in range(len(item_cat)):\n",
    "    item_category = item_cat[i]\n",
    "    query = item_category.replace(' ','+')\n",
    "\n",
    "    link  = \"https://www.amazon.in/s?k=\"+query+\"&ref=nb_sb_noss\"\n",
    "    req = requests.get(link)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    \n",
    "    urls = []\n",
    "\n",
    "    for x in range (1, last_pagination):\n",
    "        urls.append(link + '&page=' + str(x))\n",
    "\n",
    "    img_urls = list()\n",
    "    page_urls = list()\n",
    "    img_names = list()\n",
    "    names = list()\n",
    "\n",
    "    os.chdir(dirName)\n",
    "    if not os.path.exists(item_category):\n",
    "        os.mkdir(item_category+'/')\n",
    "    os.chdir(item_category+'/')\n",
    "\n",
    "    k = 1 \n",
    "    pag = 1\n",
    "    for x in urls:\n",
    "        print('Pagination : ' + str(pag))\n",
    "        req = requests.get(x,headers=headers_std).text\n",
    "        soup = BeautifulSoup(req, 'lxml')\n",
    "        imgs = soup.find_all('img',{'class':'s-image'})\n",
    "        pageurls = soup.find_all('a',{'class':\"a-link-normal s-no-outline\"})\n",
    "\n",
    "        for (pg,i) in enumerate(imgs):\n",
    "            if str(i).find('src') != -1:\n",
    "                try:\n",
    "                    page = 'https://amazon.in' + pageurls[pg]['href']\n",
    "                except IndexError:\n",
    "                    page = 'null'\n",
    "                \n",
    "                if(page=='null'):\n",
    "                    break\n",
    "                    \n",
    "                url = i['src']\n",
    "                name = i['alt']\n",
    "                names.append(name)\n",
    "                img_urls.append(url)\n",
    "                \n",
    "                page_urls.append(page)\n",
    "                \n",
    "                image_name = url.split('.')[-3].split('/')[-1]\n",
    "                img_names.append(image_name)\n",
    "                name_image_folder = image_name + '.jpg'\n",
    "                image = requests.get(url).content\n",
    "                \n",
    "                with open(name_image_folder, 'wb') as handler:\n",
    "                    handler.write(image)\n",
    "                \n",
    "            k += 1\n",
    "        pag += 1\n",
    "        \n",
    "    os.chdir(cwd)  \n",
    "\n",
    "    try:\n",
    "        df1 = pd.read_csv('amazon_data.csv')\n",
    "    except:\n",
    "        df1 = pd.DataFrame()\n",
    "\n",
    "    df2 = pd.DataFrame({'image_url' : img_urls, 'image_id': img_names, 'prod_name':names, 'page_link': page_urls})\n",
    "\n",
    "\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    df.to_csv('amazon_data.csv',index=False)\n",
    "    print(item_category+\" finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
